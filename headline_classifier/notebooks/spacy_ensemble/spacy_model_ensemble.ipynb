{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Headline Category Classifier Model Training\n",
    "\n",
    "This notebook performs the model training for a text classifier using Spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Model Type: Spacy Ensemble__\n",
    "\n",
    "This model was trained using a python v3.11.3 environment and requires:\n",
    "- spacy\n",
    "\n",
    "Please consult the requirements.txt for more info."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0. Check GPU Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2022 NVIDIA Corporation\n",
      "Built on Wed_Jun__8_16:49:14_PDT_2022\n",
      "Cuda compilation tools, release 11.7, V11.7.99\n",
      "Build cuda_11.7.r11.7/compiler.31442593_0\n"
     ]
    }
   ],
   "source": [
    "# check cuda version\n",
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Jul 12 00:53:04 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.120      Driver Version: 529.01       CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  On   | 00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   33C    P8     1W / 140W |      0MiB /  8188MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A        25      G   /Xwayland                       N/A      |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# check gpu status\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Generate config file and modify as necessary to use the correct model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;3m⚠ To generate a more effective transformer-based config (GPU-only),\n",
      "install the spacy-transformers package and re-run this command. The config\n",
      "generated now does not use transformers.\u001b[0m\n",
      "\u001b[38;5;4mℹ Generated config template specific for your use case\u001b[0m\n",
      "- Language: en\n",
      "- Pipeline: textcat\n",
      "- Optimize for: efficiency\n",
      "- Hardware: GPU\n",
      "- Transformer: None\n",
      "\u001b[38;5;2m✔ Auto-filled config with all values\u001b[0m\n",
      "\u001b[38;5;2m✔ Saved config\u001b[0m\n",
      "config.cfg\n",
      "You can now add your data and train your pipeline:\n",
      "python -m spacy train config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
     ]
    }
   ],
   "source": [
    "# setup the config file\n",
    "!python -m spacy init config --pipeline textcat config.cfg --gpu"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "modify the [model] and [model.tok2vec]\n",
    "\n",
    "```\n",
    "[components.model.linear_model]\n",
    "@architectures = \"spacy.TextCatBOW.v2\"\n",
    "exclusive_classes = true\n",
    "ngram_size = 1\n",
    "no_output_layer = false\n",
    "\n",
    "[components.model.tok2vec]\n",
    "@architectures = \"spacy.Tok2Vec.v2\"\n",
    "\n",
    "[components.model.tok2vec.embed]\n",
    "@architectures = \"spacy.MultiHashEmbed.v2\"\n",
    "width = 64\n",
    "rows = [2000, 2000, 1000, 1000, 1000, 1000]\n",
    "attrs = [\"ORTH\", \"LOWER\", \"PREFIX\", \"SUFFIX\", \"SHAPE\", \"ID\"]\n",
    "include_static_vectors = false\n",
    "\n",
    "[components.model.tok2vec.encode]\n",
    "@architectures = \"spacy.MaxoutWindowEncoder.v2\"\n",
    "width = ${model.tok2vec.embed.width}\n",
    "window_size = 1\n",
    "maxout_pieces = 3\n",
    "depth = 2\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Train the model and evaluate model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;4mℹ Saving to output directory: textcat_model\u001b[0m\n",
      "\u001b[38;5;4mℹ Using GPU: 0\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "[2023-07-12 01:06:59,290] [INFO] Set up nlp object from config\n",
      "[2023-07-12 01:06:59,297] [INFO] Pipeline: ['textcat']\n",
      "[2023-07-12 01:06:59,298] [INFO] Created vocabulary\n",
      "[2023-07-12 01:06:59,298] [INFO] Finished initializing nlp object\n",
      "[2023-07-12 01:07:16,289] [INFO] Initialized pipeline components: ['textcat']\n",
      "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "\u001b[38;5;4mℹ Pipeline: ['textcat']\u001b[0m\n",
      "\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n",
      "E    #       LOSS TEXTCAT  CATS_SCORE  SCORE \n",
      "---  ------  ------------  ----------  ------\n",
      "  0       0          0.02        1.16    0.01\n",
      "  0     200          4.45        2.75    0.03\n",
      "  0     400          4.16        5.16    0.05\n",
      "  0     600          4.09        5.85    0.06\n",
      "  0     800          4.01        8.26    0.08\n",
      "  0    1000          3.88       12.56    0.13\n",
      "  0    1200          3.69       16.04    0.16\n",
      "  0    1400          3.59       17.25    0.17\n",
      "  0    1600          3.48       21.06    0.21\n",
      "  0    1800          3.35       23.35    0.23\n",
      "  0    2000          3.32       23.20    0.23\n",
      "  0    2200          3.27       27.67    0.28\n",
      "  0    2400          3.16       28.76    0.29\n",
      "  1    2600          3.02       31.25    0.31\n",
      "  1    2800          2.90       33.85    0.34\n",
      "  1    3000          2.89       35.44    0.35\n",
      "  1    3200          2.87       35.37    0.35\n",
      "  1    3400          2.85       36.92    0.37\n",
      "  1    3600          2.84       37.35    0.37\n",
      "  2    3800          2.61       38.88    0.39\n",
      "  2    4000          2.61       39.22    0.39\n",
      "  2    4200          2.62       38.69    0.39\n",
      "  2    4400          2.64       40.17    0.40\n",
      "  2    4600          2.64       40.72    0.41\n",
      "  3    4800          2.59       40.91    0.41\n",
      "  3    5000          2.41       40.59    0.41\n",
      "  3    5200          2.47       41.31    0.41\n",
      "  3    5400          2.45       41.64    0.42\n",
      "  3    5600          2.48       41.95    0.42\n",
      "  3    5800          2.49       40.73    0.41\n",
      "  4    6000          2.33       42.18    0.42\n",
      "  4    6200          2.29       42.34    0.42\n",
      "  4    6400          2.30       42.13    0.42\n",
      "  4    6600          2.34       42.95    0.43\n",
      "  4    6800          2.31       43.04    0.43\n",
      "  5    7000          2.33       42.65    0.43\n",
      "  5    7200          2.10       42.69    0.43\n",
      "  5    7400          2.14       42.84    0.43\n",
      "  5    7600          2.21       42.44    0.42\n",
      "  5    7800          2.23       43.33    0.43\n",
      "  5    8000          2.26       43.10    0.43\n",
      "  6    8200          2.14       43.47    0.43\n",
      "  6    8400          2.03       43.56    0.44\n",
      "  6    8600          2.06       42.57    0.43\n",
      "  6    8800          2.09       43.54    0.44\n",
      "  6    9000          2.10       43.47    0.43\n",
      "  6    9200          2.16       43.04    0.43\n",
      "  7    9400          1.91       43.44    0.43\n",
      "  7    9600          1.93       43.13    0.43\n",
      "  7    9800          1.96       42.96    0.43\n",
      "  7   10000          2.01       43.24    0.43\n",
      "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
      "textcat_model/model-last\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "!python -m spacy train config.cfg --paths.train ../data/train.spacy  --paths.dev ../data/dev.spacy --output textcat_model --gpu-id 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;4mℹ Using GPU: 0\u001b[0m\n",
      "\u001b[1m\n",
      "================================== Results ==================================\u001b[0m\n",
      "\n",
      "TOK                 100.00\n",
      "TEXTCAT (macro F)   43.81 \n",
      "SPEED               6573  \n",
      "\n",
      "\u001b[1m\n",
      "=========================== Textcat F (per label) ===========================\u001b[0m\n",
      "\n",
      "                     P       R       F\n",
      "POLITICS         71.58   80.32   75.70\n",
      "WELLNESS         51.58   68.47   58.84\n",
      "ENTERTAINMENT    64.25   68.57   66.34\n",
      "TRAVEL           65.56   70.95   68.15\n",
      "HEALTHY LIVING   29.41   22.20   25.30\n",
      "BUSINESS         43.91   37.65   40.54\n",
      "WEIRD NEWS       29.89   32.50   31.14\n",
      "SPORTS           57.99   65.25   61.41\n",
      "PARENTING        52.12   52.37   52.25\n",
      "STYLE & BEAUTY   73.62   76.35   74.96\n",
      "GREEN            34.42   38.46   36.33\n",
      "FOOD & DRINK     67.30   62.52   64.83\n",
      "QUEER VOICES     66.56   65.72   66.14\n",
      "THE WORLDPOST    45.36   40.12   42.58\n",
      "HOME & LIVING    72.55   66.42   69.35\n",
      "WEDDINGS         76.65   72.85   74.70\n",
      "PARENTS          33.66   34.66   34.15\n",
      "ARTS & CULTURE   34.58   26.62   30.08\n",
      "CRIME            49.41   46.93   48.14\n",
      "CULTURE & ARTS   49.09   31.40   38.30\n",
      "ENVIRONMENT      36.36   21.05   26.67\n",
      "COMEDY           50.75   42.32   46.15\n",
      "RELIGION         45.31   44.96   45.14\n",
      "MONEY            45.86   36.97   40.94\n",
      "BLACK VOICES     45.04   38.80   41.69\n",
      "COLLEGE          39.24   28.18   32.80\n",
      "DIVORCE          68.62   66.86   67.73\n",
      "U.S. NEWS        19.61    8.77   12.12\n",
      "WORLD NEWS       42.25   34.58   38.03\n",
      "IMPACT           30.33   20.65   24.57\n",
      "STYLE            34.83   32.71   33.73\n",
      "EDUCATION        36.99   25.00   29.83\n",
      "WORLDPOST        32.09   34.40   33.20\n",
      "SCIENCE          61.33   40.89   49.07\n",
      "TASTE            30.96   33.52   32.19\n",
      "TECH             47.95   39.81   43.50\n",
      "WOMEN            32.92   30.88   31.87\n",
      "GOOD NEWS        26.74   15.75   19.83\n",
      "FIFTY            36.99   20.45   26.34\n",
      "ARTS             23.75   14.96   18.36\n",
      "MEDIA            49.61   44.56   46.95\n",
      "LATINO VOICES    52.05   32.76   40.21\n",
      "\n",
      "\u001b[1m\n",
      "======================== Textcat ROC AUC (per label) ========================\u001b[0m\n",
      "\n",
      "                 ROC AUC\n",
      "POLITICS            0.95\n",
      "WELLNESS            0.94\n",
      "ENTERTAINMENT       0.95\n",
      "TRAVEL              0.96\n",
      "HEALTHY LIVING      0.91\n",
      "BUSINESS            0.91\n",
      "WEIRD NEWS          0.91\n",
      "SPORTS              0.95\n",
      "PARENTING           0.94\n",
      "STYLE & BEAUTY      0.98\n",
      "GREEN               0.94\n",
      "FOOD & DRINK        0.97\n",
      "QUEER VOICES        0.94\n",
      "THE WORLDPOST       0.96\n",
      "HOME & LIVING       0.96\n",
      "WEDDINGS            0.97\n",
      "PARENTS             0.94\n",
      "ARTS & CULTURE      0.92\n",
      "CRIME               0.95\n",
      "CULTURE & ARTS      0.92\n",
      "ENVIRONMENT         0.94\n",
      "COMEDY              0.90\n",
      "RELIGION            0.91\n",
      "MONEY               0.93\n",
      "BLACK VOICES        0.92\n",
      "COLLEGE             0.92\n",
      "DIVORCE             0.96\n",
      "U.S. NEWS           0.91\n",
      "WORLD NEWS          0.95\n",
      "IMPACT              0.87\n",
      "STYLE               0.92\n",
      "EDUCATION           0.93\n",
      "WORLDPOST           0.94\n",
      "SCIENCE             0.94\n",
      "TASTE               0.96\n",
      "TECH                0.92\n",
      "WOMEN               0.88\n",
      "GOOD NEWS           0.92\n",
      "FIFTY               0.90\n",
      "ARTS                0.91\n",
      "MEDIA               0.93\n",
      "LATINO VOICES       0.88\n",
      "\n",
      "\u001b[38;5;2m✔ Saved results to textcat_model/metrics.json\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "!python -m spacy evaluate ./textcat_model/model-best/ --output ./textcat_model/metrics.json ../data/test.spacy --gpu-id 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'POLITICS': 0.07092093676328659, 'WELLNESS': 0.0028532857540994883, 'ENTERTAINMENT': 0.005385665223002434, 'TRAVEL': 0.045635074377059937, 'HEALTHY LIVING': 0.0006666149711236358, 'BUSINESS': 0.005303025245666504, 'WEIRD NEWS': 0.0005795331089757383, 'SPORTS': 0.0005500675761140883, 'PARENTING': 0.004485529847443104, 'STYLE & BEAUTY': 0.0014961593551561236, 'GREEN': 0.011978158727288246, 'FOOD & DRINK': 0.0002930395130533725, 'QUEER VOICES': 0.016649233177304268, 'THE WORLDPOST': 0.012198668904602528, 'HOME & LIVING': 0.0004385566571727395, 'WEDDINGS': 0.0005049843457527459, 'PARENTS': 0.0014251680113375187, 'ARTS & CULTURE': 0.0020301323384046555, 'CRIME': 0.0017437454080209136, 'CULTURE & ARTS': 0.012227863073348999, 'ENVIRONMENT': 0.005559844896197319, 'COMEDY': 0.0013016789453104138, 'RELIGION': 0.020096885040402412, 'MONEY': 0.0003741745313163847, 'BLACK VOICES': 0.009691660292446613, 'COLLEGE': 0.0013013698626309633, 'DIVORCE': 0.0010543664684519172, 'U.S. NEWS': 0.00018205470405519009, 'WORLD NEWS': 0.005822456441819668, 'IMPACT': 0.031314365565776825, 'STYLE': 0.0007754872785881162, 'EDUCATION': 0.003718551015481353, 'WORLDPOST': 0.6662241816520691, 'SCIENCE': 0.0009662533411756158, 'TASTE': 7.695327803958207e-05, 'TECH': 0.0035481040831655264, 'WOMEN': 0.0013573289616033435, 'GOOD NEWS': 0.000516930129379034, 'FIFTY': 0.00023329984105657786, 'ARTS': 0.04159436374902725, 'MEDIA': 0.0038778302259743214, 'LATINO VOICES': 0.0030464257579296827}\n"
     ]
    }
   ],
   "source": [
    "# check results\n",
    "import spacy\n",
    "nlp = spacy.load(\"textcat_model/model-best\")\n",
    "doc=nlp(\"History is made: 10 new UK attractions for day trips and short breaks\")\n",
    "print(doc.cats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'WORLDPOST'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(doc.cats, key=doc.cats.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.004485529847443104"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.cats[\"PARENTING\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Package the model into a Zip file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zip up the model-best\n",
    "\n",
    "import shutil\n",
    "\n",
    "model_best_path = \"textcat_model/model-best\"\n",
    "zipfile_name = \"textcat_model/model-best\"\n",
    "\n",
    "shutil.make_archive(zipfile_name, \"zip\", model_best_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Note:__ To preserve models, please rename the folder. For example, \"textcat_model\" > \"textcat_model_2023-07-17_12-24\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spacy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
