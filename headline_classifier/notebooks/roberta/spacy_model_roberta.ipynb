{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Headline Category Classifier Model Training\n",
    "\n",
    "This notebook performs the model training for a text classifier using Spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Model Type: RoBERTa__\n",
    "\n",
    "This model was trained using a python v3.11.3 environment and requires:\n",
    "- spacy\n",
    "- spacy-transformers\n",
    "\n",
    "Please consult the requirements.txt for more info."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0. Check GPU Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2022 NVIDIA Corporation\n",
      "Built on Wed_Jun__8_16:49:14_PDT_2022\n",
      "Cuda compilation tools, release 11.7, V11.7.99\n",
      "Build cuda_11.7.r11.7/compiler.31442593_0\n"
     ]
    }
   ],
   "source": [
    "# check cuda and gpu status\n",
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Jun 23 15:08:06 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.120      Driver Version: 529.01       CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  On   | 00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   41C    P8     1W / 115W |      0MiB /  8188MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A        25      G   /Xwayland                       N/A      |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Generate config file and modify as necessary to use the correct model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;4mℹ Generated config template specific for your use case\u001b[0m\n",
      "- Language: en\n",
      "- Pipeline: textcat\n",
      "- Optimize for: efficiency\n",
      "- Hardware: GPU\n",
      "- Transformer: roberta-base\n",
      "\u001b[38;5;2m✔ Auto-filled config with all values\u001b[0m\n",
      "\u001b[38;5;2m✔ Saved config\u001b[0m\n",
      "config_transformer.cfg\n",
      "You can now add your data and train your pipeline:\n",
      "python -m spacy train config_transformer.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
     ]
    }
   ],
   "source": [
    "# setup the config file\n",
    "!python -m spacy init config --pipeline textcat config_transformer.cfg --gpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Train the model and evaluate model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Created output directory: textcat_model_transformer\u001b[0m\n",
      "\u001b[38;5;4mℹ Saving to output directory: textcat_model_transformer\u001b[0m\n",
      "\u001b[38;5;4mℹ Using GPU: 0\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "[2023-06-23 15:09:58,739] [INFO] Set up nlp object from config\n",
      "[2023-06-23 15:09:58,746] [INFO] Pipeline: ['transformer', 'textcat']\n",
      "[2023-06-23 15:09:58,748] [INFO] Created vocabulary\n",
      "[2023-06-23 15:09:58,749] [INFO] Finished initializing nlp object\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "[2023-06-23 15:10:17,189] [INFO] Initialized pipeline components: ['transformer', 'textcat']\n",
      "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "\u001b[38;5;4mℹ Pipeline: ['transformer', 'textcat']\u001b[0m\n",
      "\u001b[38;5;4mℹ Initial learn rate: 0.0\u001b[0m\n",
      "E    #       LOSS TRANS...  LOSS TEXTCAT  CATS_SCORE  SCORE \n",
      "---  ------  -------------  ------------  ----------  ------\n",
      "  0       0           0.00          0.07        0.68    0.01\n",
      "  0     200           1.65         14.21        5.16    0.05\n",
      "  0     400          16.27         11.72       21.65    0.22\n",
      "  0     600          34.11          9.61       28.68    0.29\n",
      "  0     800          47.12          8.54       34.73    0.35\n",
      "  0    1000          56.17          8.29       38.77    0.39\n",
      "  1    1200          60.18          7.27       41.71    0.42\n",
      "  1    1400          70.02          7.35       43.48    0.43\n",
      "  1    1600          75.04          7.10       45.92    0.46\n",
      "  1    1800          80.27          7.13       47.73    0.48\n",
      "  1    2000          83.95          7.08       48.17    0.48\n",
      "  2    2200          83.88          6.59       49.58    0.50\n",
      "  2    2400          84.79          5.88       50.04    0.50\n",
      "  2    2600          86.81          5.96       50.41    0.50\n"
     ]
    }
   ],
   "source": [
    "# train them model\n",
    "!python -m spacy train config_transformer.cfg --paths.train ../data/train.spacy  --paths.dev ../data/dev.spacy --output textcat_model_transformer --gpu-id 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;4mℹ Using GPU: 0\u001b[0m\n",
      "\u001b[1m\n",
      "================================== Results ==================================\u001b[0m\n",
      "\n",
      "TOK                 100.00\n",
      "TEXTCAT (macro F)   50.21 \n",
      "SPEED               4085  \n",
      "\n",
      "\u001b[1m\n",
      "=========================== Textcat F (per label) ===========================\u001b[0m\n",
      "\n",
      "                     P       R       F\n",
      "POLITICS         79.07   81.26   80.15\n",
      "WELLNESS         60.10   67.61   63.63\n",
      "ENTERTAINMENT    69.20   76.56   72.70\n",
      "TRAVEL           81.66   79.68   80.66\n",
      "HEALTHY LIVING   33.61   26.32   29.52\n",
      "BUSINESS         49.92   54.06   51.91\n",
      "WEIRD NEWS       45.92   37.50   41.28\n",
      "SPORTS           65.77   78.79   71.69\n",
      "PARENTING        61.17   55.81   58.36\n",
      "STYLE & BEAUTY   72.98   84.19   78.19\n",
      "GREEN            40.25   51.82   45.31\n",
      "FOOD & DRINK     68.67   70.87   69.76\n",
      "QUEER VOICES     73.00   71.86   72.42\n",
      "THE WORLDPOST    41.33   64.44   50.36\n",
      "HOME & LIVING    82.29   71.64   76.60\n",
      "WEDDINGS         81.84   76.50   79.08\n",
      "PARENTS          47.04   35.66   40.57\n",
      "ARTS & CULTURE   40.00   37.41   38.66\n",
      "CRIME            66.21   54.19   59.60\n",
      "CULTURE & ARTS   43.42   38.37   40.74\n",
      "ENVIRONMENT      70.00   15.79   25.77\n",
      "COMEDY           60.61   45.64   52.07\n",
      "RELIGION         50.00   57.75   53.60\n",
      "MONEY            58.33   42.42   49.12\n",
      "BLACK VOICES     52.86   44.80   48.50\n",
      "COLLEGE          34.72   45.45   39.37\n",
      "DIVORCE          86.38   63.43   73.15\n",
      "U.S. NEWS        19.23    4.39    7.14\n",
      "WORLD NEWS       37.74   23.05   28.62\n",
      "IMPACT           32.62   29.35   30.90\n",
      "STYLE            44.52   30.37   36.11\n",
      "EDUCATION        37.61   37.96   37.79\n",
      "WORLDPOST        39.01   34.80   36.79\n",
      "SCIENCE          55.69   60.89   58.17\n",
      "TASTE            37.12   46.70   41.36\n",
      "TECH             46.76   49.03   47.87\n",
      "WOMEN            31.74   37.06   34.19\n",
      "GOOD NEWS        58.33   23.97   33.98\n",
      "FIFTY            63.33   28.79   39.58\n",
      "ARTS             21.55   39.37   27.86\n",
      "MEDIA            53.24   66.32   59.06\n",
      "LATINO VOICES    40.25   55.17   46.55\n",
      "\n",
      "\u001b[1m\n",
      "======================== Textcat ROC AUC (per label) ========================\u001b[0m\n",
      "\n",
      "                 ROC AUC\n",
      "POLITICS            0.97\n",
      "WELLNESS            0.96\n",
      "ENTERTAINMENT       0.97\n",
      "TRAVEL              0.98\n",
      "HEALTHY LIVING      0.93\n",
      "BUSINESS            0.95\n",
      "WEIRD NEWS          0.96\n",
      "SPORTS              0.97\n",
      "PARENTING           0.96\n",
      "STYLE & BEAUTY      0.99\n",
      "GREEN               0.95\n",
      "FOOD & DRINK        0.99\n",
      "QUEER VOICES        0.96\n",
      "THE WORLDPOST       0.97\n",
      "HOME & LIVING       0.98\n",
      "WEDDINGS            0.99\n",
      "PARENTS             0.96\n",
      "ARTS & CULTURE      0.96\n",
      "CRIME               0.98\n",
      "CULTURE & ARTS      0.96\n",
      "ENVIRONMENT         0.97\n",
      "COMEDY              0.93\n",
      "RELIGION            0.96\n",
      "MONEY               0.96\n",
      "BLACK VOICES        0.94\n",
      "COLLEGE             0.95\n",
      "DIVORCE             0.97\n",
      "U.S. NEWS           0.92\n",
      "WORLD NEWS          0.97\n",
      "IMPACT              0.91\n",
      "STYLE               0.97\n",
      "EDUCATION           0.95\n",
      "WORLDPOST           0.96\n",
      "SCIENCE             0.97\n",
      "TASTE               0.98\n",
      "TECH                0.96\n",
      "WOMEN               0.93\n",
      "GOOD NEWS           0.95\n",
      "FIFTY               0.92\n",
      "ARTS                0.94\n",
      "MEDIA               0.97\n",
      "LATINO VOICES       0.95\n",
      "\n",
      "\u001b[38;5;2m✔ Saved results to metrics_transformer.json\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "!python -m spacy evaluate ./textcat_model_transformer/model-best/ --output ./metrics_transformer.json ../data/test.spacy --gpu-id 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'POLITICS': 0.00022873641864862293, 'WELLNESS': 0.0008439306984655559, 'ENTERTAINMENT': 0.00024795858189463615, 'TRAVEL': 0.9911842942237854, 'HEALTHY LIVING': 0.00013403574121184647, 'BUSINESS': 0.0006679550861008465, 'WEIRD NEWS': 0.00028393309912644327, 'SPORTS': 0.00016008797683753073, 'PARENTING': 0.00030838174279779196, 'STYLE & BEAUTY': 0.00044757052091881633, 'GREEN': 0.00022121783695183694, 'FOOD & DRINK': 0.0008898158557713032, 'QUEER VOICES': 4.772236934513785e-05, 'THE WORLDPOST': 5.8274436014471576e-05, 'HOME & LIVING': 0.00030177002190612257, 'WEDDINGS': 0.00015639951743651181, 'PARENTS': 7.467636896762997e-05, 'ARTS & CULTURE': 4.363317566458136e-05, 'CRIME': 6.480376760009676e-05, 'CULTURE & ARTS': 0.00033347454154863954, 'ENVIRONMENT': 0.0003155650629196316, 'COMEDY': 0.00018637241737451404, 'RELIGION': 0.00012191912537673488, 'MONEY': 0.00019806383352261037, 'BLACK VOICES': 7.40106261218898e-05, 'COLLEGE': 5.0833878049161285e-05, 'DIVORCE': 6.233305612113327e-05, 'U.S. NEWS': 4.230613194522448e-05, 'WORLD NEWS': 5.738640538766049e-05, 'IMPACT': 0.00021989482047501951, 'STYLE': 0.00010583067341940477, 'EDUCATION': 4.942881423630752e-05, 'WORLDPOST': 0.00038716805283911526, 'SCIENCE': 8.31049183034338e-05, 'TASTE': 0.00015555745630990714, 'TECH': 7.463066140189767e-05, 'WOMEN': 3.091347753070295e-05, 'GOOD NEWS': 8.01008427515626e-05, 'FIFTY': 0.0001943300012499094, 'ARTS': 0.0007277861004695296, 'MEDIA': 3.6984165490139276e-05, 'LATINO VOICES': 4.6771227061981335e-05}\n"
     ]
    }
   ],
   "source": [
    "# check results\n",
    "import spacy\n",
    "nlp = spacy.load(\"textcat_model_transformer/model-best\")\n",
    "doc=nlp(\"History is made: 10 new UK attractions for day trips and short breaks\")\n",
    "print(doc.cats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TRAVEL'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(doc.cats, key=doc.cats.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9911842942237854"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.cats[\"TRAVEL\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Package the model into a Zip file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zip up the model-best\n",
    "\n",
    "import shutil\n",
    "\n",
    "model_best_path = \"textcat_model_transformer/model-best\"\n",
    "zipfile_name = \"textcat_model_transformer/model-best\"\n",
    "\n",
    "shutil.make_archive(zipfile_name, \"zip\", model_best_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Note:__ To preserve models, please rename the folder. For example, \"textcat_model_transformer\" > \"textcat_model_transformer_2023-07-17_12-24\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spacy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
